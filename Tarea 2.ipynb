{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2: análisis de sentimientos usando aprendizaje supervisado\n",
    "\n",
    "##### Por: Daniela Flores Villanueva \n",
    "\n",
    "## Sobre las librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se cargan todas las librerías empleadas en esta tarea:\n",
    "- `pandas`: librería utilizada para cargar la matriz GloVe y posteriormente, para confeccionar un `DataFrame` con palabras y su sentimiento asociado.\n",
    "- `csv`: utilizada para cargar los vectores, según lo dispuesto en [este](https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python) sitio.\n",
    "- `nltk`: se usó para cargar el *opinion lexicon* descrito en el enunciado de manera conveniente. Se probó además sus métodos para realizar lematización, proceso que consiste en, dada una palabra flexionada (en forma plural, verbo conjugado, etc), encontrar su lema, es decir, algo similar a la forma en que sería encontrada en un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"opinion_lexicon\")\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_PATH = \"./glove.42B.300d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_WORDS = list(punctuation)\n",
    "NON_WORDS.extend(map(str, range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOPWORDS = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma de cargar el opinion lexicon es la descrita en la [documentación](http://www.nltk.org/api/nltk.corpus.reader.html?highlight=wordnet) de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = opinion_lexicon.positive()\n",
    "negative_data = opinion_lexicon.negative()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de tener una representación más general de las palabras, se convierte cada vocablo en las listas anteriores a minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = [word.lower() for word in positive_data]\n",
    "negative_data = [word.lower() for word in negative_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se carga la matriz de *embeddings*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_matrix = pd.read_csv(GLOVE_PATH, sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE, na_values=None, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el mismo recurso para cargar la matriz en memoria (adjunto en la descripción de las librerías utilizadas), se menciona una función que, dada una palabra, retorna su *embedding*. Esta función es `vec(w)`, definida a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(w): \n",
    "    return glove_matrix.loc[w].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breve análisis exploratorio\n",
    "\n",
    "No se puede empezar a trabajar sin tener al menos una noción básica de la composición de la matriz y de las palabras con etiqueta. Por esta razón, en primer lugar cabe preguntarse cuántas palabras hay en la matriz de *embeddings*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_words = set(glove_matrix.index.tolist())\n",
    "print(len(glove_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podría ocurrir que no todas las palabras que tenemos etiquetadas según su polaridad tengan su representación vectorial en GloVe, por lo que conviene realizar el siguiente análisis:\n",
    "Dada la unión entre las palabras de polaridad positiva y las de polaridad negativa, se revisa si están o no en la matriz. De no estar, se agregan a la lista `missing_words`, para decidir qué hacer con ellas futuramente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words = set()\n",
    "for word in set(positive_data).union(set(negative_data)):\n",
    "    if word not in glove_words:\n",
    "        missing_words.add(word)\n",
    "print(len(missing_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible notar que hay 161 palabras del *opinion lexicon* para las que no se tiene una representación vectorial. Antes de decidir qué hacer con estas palabras faltantes, conviene preguntarse si existen palabras que estén etiquetadas tanto de polaridad positiva como de polaridad negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_tag = set(positive_data).intersection(negative_data)\n",
    "print(wrong_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, se evidencia que tres palabras relacionadas a la envidia parecen estar mal etiquetadas, pues no deberían aparecer entre las palabras positivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se procede a realizar lematización de los vocablos positivos y negativos, para ver si existe algún cambio en la cantidad palabras sin *embedding* tras este cambio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data_lemmatized = {nltk.stem.WordNetLemmatizer().lemmatize(word) for word in positive_data}\n",
    "negative_data_lemmatized = {nltk.stem.WordNetLemmatizer().lemmatize(word) for word in negative_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words_lemmatized = set()\n",
    "for word in positive_data_lemmatized.union(set(negative_data_lemmatized)):\n",
    "    if word not in glove_words:\n",
    "        missing_words_lemmatized.add(word)\n",
    "print(len(missing_words_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_tag_lemmatized = set(positive_data_lemmatized).intersection(negative_data_lemmatized)\n",
    "print(wrong_tag_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data_lemmatized = positive_data_lemmatized - wrong_tag_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al lematizar, es posible notar que hay una palabra menos que no tiene representación vectorial. En la siguiente celda, podrá evidenciarse qué palabra es la que hace la diferencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(missing_words - missing_words_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/stanfordnlp/GloVe/search?utf8=%E2%9C%93&q=unk&type="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_matrix = np.empty((0, 300))\n",
    "for word in positive_data_lemmatized:\n",
    "    if word in glove_words:\n",
    "        positive_matrix = np.append(positive_matrix, [vec(word)], axis=0)\n",
    "    else:\n",
    "        positive_matrix = np.append(positive_matrix, [vec(\"unk\")], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_matrix = np.empty((0, 300))\n",
    "for word in negative_data_lemmatized:\n",
    "    if word in glove_words:\n",
    "        negative_matrix = np.append(negative_matrix, [vec(word)], axis=0)\n",
    "    else:\n",
    "        negative_matrix = np.append(negative_matrix, [vec(\"unk\")], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positive_matrix.shape)\n",
    "print(negative_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_labels = [1] * positive_matrix.shape[0]\n",
    "negative_labels = [0] * negative_matrix.shape[0]\n",
    "all_labels = positive_labels + negative_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_matrix = np.concatenate([positive_matrix, negative_matrix], axis=0)\n",
    "concatenated_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación\n",
    "\n",
    "### Separación entre entrenamiento y *testing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(concatenated_matrix, all_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimator_grid_search(estimator, parameters):\n",
    "    clf = GridSearchCV(estimator=estimator, param_grid=parameters, n_jobs=-1, cv=10)\n",
    "    clf.fit(X_train, y_train)   \n",
    "    print(\"Mejor accuracy: {}\".format(clf.best_score_))\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(clf, X_test, y_test):\n",
    "    metrics = {}\n",
    "    predictions = clf.predict(X_test)\n",
    "    metrics[\"accuracy\"] = accuracy_score(y_test, predictions)\n",
    "    metrics[\"precision\"] = precision_score(y_test, predictions)\n",
    "    metrics[\"recall\"] = recall_score(y_test, predictions)\n",
    "    metrics[\"f1-score\"] = f1_score(y_test, predictions)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(clf, clf_name):\n",
    "    joblib.dump(clf, \"best_{}.pkl\".format(clf_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {\n",
    "    \"C\": [1, 10],\n",
    "    \"gamma\": [0.001, 0.0001],\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "}\n",
    "tuning_svm = estimator_grid_search(SVC(), svm_params)\n",
    "print(\"Mejor C: {}\".format(tuning_svm.best_estimator_.C))\n",
    "print(\"Mejor kernel: {}\".format(tuning_svm.best_estimator_.kernel))\n",
    "print(\"Mejor Gamma: {}\".format(tuning_svm.best_estimator_.gamma))\n",
    "final_svm = SVC(C=tuning_svm.best_estimator_.C, \n",
    "                kernel=tuning_svm.best_estimator_.kernel, \n",
    "                gamma=tuning_svm.best_estimator_.gamma, probability=True)\n",
    "final_svm.fit(X_train, y_train)\n",
    "svm_final_metrics = get_metrics(final_svm, X_test, y_test)\n",
    "print(svm_final_metrics)\n",
    "save_model(final_svm, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\"n_neighbors\": np.arange(5) + 1, \"algorithm\": [\"kd_tree\", \"ball_tree\"]}\n",
    "tuning_knn = estimator_grid_search(KNeighborsClassifier(), knn_params)\n",
    "print(\"Mejor K: {}\".format(tuning_knn.best_estimator_.n_neighbors)) \n",
    "print(\"Mejor algoritmo de búsqueda de vecinos: {}\".format(tuning_knn.best_estimator_.algorithm))\n",
    "final_knn = KNeighborsClassifier(n_neighbors=tuning_knn.best_estimator_.n_neighbors, \n",
    "                                 algorithm=tuning_knn.best_estimator_.algorithm)\n",
    "final_knn.fit(X_train, y_train)\n",
    "knn_final_metrics = get_metrics(final_knn, X_test, y_test)\n",
    "print(knn_final_metrics)\n",
    "save_model(final_knn, \"KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    \"n_estimators\": np.arange(10) + 1, \n",
    "    \"criterion\": [\"gini\", \"entropy\"], \n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]}\n",
    "tuning_rf = estimator_grid_search(RandomForestClassifier(), rf_params)\n",
    "print(\"Mejor cantidad de árboles: {}\".format(tuning_rf.best_estimator_.n_estimators))\n",
    "print(\"Mejor criterio de división: {}\".format(tuning_rf.best_estimator_.criterion))\n",
    "print(\"Mejor cantidad máxima de features: {}\".format(tuning_rf.best_estimator_.max_features))\n",
    "final_rf = RandomForestClassifier(n_estimators=tuning_rf.best_estimator_.n_estimators,\n",
    "                                 criterion=tuning_rf.best_estimator_.criterion,\n",
    "                                 max_features=tuning_rf.best_estimator_.max_features)\n",
    "final_rf.fit(X_train, y_train)\n",
    "rf_final_metrics = get_metrics(final_rf, X_test, y_test)\n",
    "print(rf_final_metrics)\n",
    "save_model(final_rf, \"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(clf, test_set):\n",
    "    return clf.predict_proba(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pequeña prueba de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = [\"italian\", \"mexican\", \"black\"]\n",
    "test_words_matrix = np.empty((0, 300))\n",
    "for word in test_words:\n",
    "    test_words_matrix = np.append(test_words_matrix, [vec(word)], axis=0)\n",
    "print(\"SVM: {}\".format(model_predict(final_svm, test_words_matrix)))\n",
    "print(\"KNN: {}\".format(model_predict(final_knn, test_words_matrix)))\n",
    "print(\"Random Forest: {}\".format(model_predict(final_rf, test_words_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_knn.predict(test_words_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción de oraciones\n",
    "\n",
    "### Preprocesamiento de las oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    words_sentence = ''.join([c for c in sentence if c not in NON_WORDS])\n",
    "    tokenized_sentence = word_tokenize(words_sentence)\n",
    "    removed_stopwords = [word for word in tokenized_sentence if word not in ENGLISH_STOPWORDS]\n",
    "    lemmatized_sentence = [nltk.stem.WordNetLemmatizer().lemmatize(word) for word in removed_stopwords]\n",
    "    return tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence(sentence):\n",
    "    sentence_matrix = np.empty((0, 300))\n",
    "    for word in sentence:\n",
    "        if word in glove_words:\n",
    "            sentence_matrix = np.append(sentence_matrix, [vec(word)], axis=0)\n",
    "        else:\n",
    "            sentence_matrix = np.append(sentence_matrix, [vec(\"unk\")], axis=0)\n",
    "    mean_sentence_vector = sentence_matrix.mean(0)\n",
    "    if np.isnan(np.sum(mean_sentence_vector)):\n",
    "        mean_sentence_vector = vec(\"unk\")\n",
    "    return mean_sentence_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentence(sentence):\n",
    "    tokenized = tokenize_lemmatize(sentence)\n",
    "    vectorized = vectorize_sentence(tokenized)\n",
    "    return vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pequeña prueba de predicción de oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_svm = joblib.load(\"best_SVM.pkl\")\n",
    "print(model_predict(best_svm, list(map(prepare_sentence, [\"Let's go get mexican food\", \n",
    "                                                    \"Let's go get italian food\", \n",
    "                                                    \"You're a faggot\", \n",
    "                                                    \"You are amazing\", \n",
    "                                                    \"You're amazing\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo sobre frases reales\n",
    "https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = pd.read_csv(\"amazon_cells_labelled.txt\", sep=\"\\t\", names=[\"sentence\", \"polarity\"])\n",
    "imdb = pd.read_csv(\"imdb_labelled.txt\", sep=\"\\t\", names=[\"sentence\", \"polarity\"])\n",
    "yelp = pd.read_csv(\"yelp_labelled.txt\", sep=\"\\t\", names=[\"sentence\", \"polarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = pd.concat([amazon, imdb, yelp], sort=False)\n",
    "all_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sentence_test = all_sentences[\"sentence\"].tolist()\n",
    "y_sentence_test = all_sentences[\"polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sentences = list(map(prepare_sentence, X_sentence_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences_matrix = np.empty((0, 300))\n",
    "for sentence in X_sentence_test:\n",
    "    vectorized_sentence = prepare_sentence(sentence)\n",
    "    new_sentences_matrix = np.append(new_sentences_matrix, [vec(\"unk\")], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_concatenated_matrix = np.concatenate([positive_matrix, negative_matrix, new_sentences_matrix], axis=0)\n",
    "new_all_labels = positive_labels + negative_labels + y_sentence_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_concatenated_matrix, new_all_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_svm = SVC(C=tuning_svm.best_estimator_.C, \n",
    "                kernel=tuning_svm.best_estimator_.kernel, \n",
    "                gamma=tuning_svm.best_estimator_.gamma, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_svm.fit(new_X_train, new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_svm_final_metrics = get_metrics(final_svm, new_X_test, new_y_test)\n",
    "print(new_svm_final_metrics)\n",
    "save_model(new_svm, \"sentences_SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
